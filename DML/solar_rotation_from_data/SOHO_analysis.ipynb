{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOHO analysis \n",
    "The purpose of this notebook is to analysis visual-spectrum images of the sun from the SOHO imaging satellite at the L1 Lagrange point (meaning the images are from the same perspective as the Earth) and use this data to determine the rotational period of the sun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "\n",
    "- [ ] README.txt\n",
    "   \n",
    "    ~~--SDO/HMI satellite~~\n",
    "\n",
    "    ~~--using JSOC API for data access~~\n",
    "    ~~-- using VSO api through sunpy~~\n",
    "~~- [ ] Make file importing work~~\n",
    "- [ ] Perform analysis on data\n",
    "    - [ ] Plot velocity for each point with error bars\n",
    "    - [ ] Plot velocity against latitude\n",
    "    - [ ] Plot velocity against longitude (possible warping)\n",
    "    - [ ] Plot velocity against longitude and latitude (polar coords) and hopefully reconstruct an image of the sun with velocities.\n",
    "    - [ ] Interpolations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, Dropdown\n",
    "import cv2\n",
    "from astropy.coordinates import SkyCoord\n",
    "import json\n",
    "\n",
    "from utils.data import fetch_images, get_files_with_times\n",
    "from utils.image_processing import detect_sunspots\n",
    "from utils.feature_tracking import SunspotTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...:  40%|████      | 96/240 [00:00<00:00, 257.59img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achtung! Image not available: https://soho.nascom.nasa.gov/data/REPROCESSING/Completed/2025/hmiigr/20250427/20250427_2230_hmiigr_512.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...:  51%|█████     | 122/240 [00:10<00:13,  8.97img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error at 2025-04-28 00:00:00: HTTPSConnectionPool(host='soho.nascom.nasa.gov', port=443): Read timed out. (read timeout=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...:  94%|█████████▍| 225/240 [00:12<00:00, 17.97img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_0000.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_0130.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_0300.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_0430.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...:  95%|█████████▌| 229/240 [00:30<00:02,  5.01img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_0600.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...:  96%|█████████▌| 230/240 [00:31<00:02,  4.68img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_0730.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_0900.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_1030.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_1200.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...:  98%|█████████▊| 234/240 [00:51<00:03,  1.97img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_1330.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...:  98%|█████████▊| 235/240 [00:56<00:03,  1.63img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_1500.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_1630.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_1800.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_1930.jpg\n",
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_2100.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading HMI images...: 100%|██████████| 240/240 [01:11<00:00,  3.38img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully downloaded sdo_hmi_jpgs/20250506/20250506_2230.jpg\n",
      "All requested files successfully downloaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Parameters\n",
    "data_bank_url = \"https://soho.nascom.nasa.gov/data/REPROCESSING/Completed/2025/hmiigr/\"\n",
    "save_dir = \"sdo_hmi_jpgs\"\n",
    "start_date = datetime(2025,4,22,0,0)\n",
    "end_date = datetime(2025,5,7,0,0)\n",
    "cadence = timedelta(hours=1.5)\n",
    "\n",
    "#Download the images\n",
    "fetch_images(\n",
    "    data_bank_url, \n",
    "    save_dir, \n",
    "    start_date, \n",
    "    end_date, \n",
    "    cadence,\n",
    "    )\n",
    "\n",
    "#Collect the images\n",
    "file_paths, times = get_files_with_times(save_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of data processing is preprocessing and identification of the sunspots. This is done via the utility `image_processing.py`. The utility uses contouring to identify the centroids of features on the sun which *should* correspond well to the sunspots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7521d0bec4b4b32a57491e60688977f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Day:', options=('20250422', '20250423', '20250424', '202504…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dropdown to select days\n",
    "day_dirs = sorted([d for d in os.listdir(\"sdo_hmi_jpgs\") if os.path.isdir(os.path.join(\"sdo_hmi_jpgs\", d))])\n",
    "@interact(day=Dropdown(options=day_dirs, description=\"Select Day:\"))\n",
    "def show_day_images(day):\n",
    "    day_path = os.path.join(\"sdo_hmi_jpgs\", day)\n",
    "    files = sorted([f for f in os.listdir(day_path) if f.endswith(\".jpg\")])[:16] #Only the first 12 images\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "    for ax, file in zip(axes.flat, files):\n",
    "        img, centroids, _, _ = detect_sunspots(os.path.join(day_path, file))\n",
    "        print(centroids)\n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.scatter([c[0] for c in centroids], [c[1] for c in centroids], s=5, c='blue')\n",
    "        ax.set_title(file.split('_')[1])  # Show time (hhmm)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization above includes a drop down to select the day of choice and then the image represents all data (including coordinates at the top) collected from that date. The sunspot centroids are shown via blue dots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part of the data analysis involves tracking the sunspots between frames. This was quite a complicated process with a decent amount of trial and error, but the main issue I faced was actually an error in using Carrington coordinates instead of Stony coordinates. This meant that all of my velocities were centered around 0 as Carrington is a rotating reference frame where the same point on the sun would move as the Earth orbited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This block computes the longitudinal angular-velocity of the sunspots between different\n",
    "images via a nearst neighbour algorithm. The data is saved in a JSON file called sunspot_data.json.\n",
    "'''\n",
    "\n",
    "def skycoord_to_dict(coord):\n",
    "    #This function is for saving to JSON\n",
    "    return {\n",
    "        'lon': coord.lon.deg,\n",
    "        'lat': coord.lat.deg,\n",
    "        'frame': coord.frame.name,\n",
    "        'unit': 'deg'\n",
    "    }\n",
    "\n",
    "_, _, solar_center, solar_radius = detect_sunspots(file_paths[0]) #Initial value for solar radius from the first image\n",
    "tracker = SunspotTracker(solar_center, solar_radius, 1)\n",
    "\n",
    "#main feature tracking loop\n",
    "for img, time in zip(file_paths, times):\n",
    "    img, centroids, solar_center, solar_radius = detect_sunspots(img)\n",
    "    \n",
    "    tracker.process_frame(time, centroids)\n",
    "\n",
    "#Filter the data to only include tracks with one or more velocities\n",
    "filtered_tracks = [t for t in tracker.tracks if len(t['velocities']) >= 1]\n",
    "\n",
    "###Write the data to JSON\n",
    "#First convert necessary datatypes to str\n",
    "for entry in filtered_tracks:\n",
    "    if 'times' in entry:\n",
    "        entry['times'] = [t.isoformat() if isinstance(t, datetime) else t for t in entry['times']]\n",
    "    if 'positions_helio' in entry:\n",
    "        entry['positions_helio'] = [skycoord_to_dict(coord) if isinstance(coord, SkyCoord) else coord for coord in entry['positions_helio']]\n",
    "\n",
    "with open(file='sunspot_data.json',mode='w') as f:\n",
    "    json.dump(filtered_tracks, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is saved into a JSON file and then the following codeblock is used to extract the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code is to recover the data from the JSON\n",
    "'''\n",
    "\n",
    "def dict_to_skycoord(d):\n",
    "    return SkyCoord(lon=d['lon'], lat=d['lat'],\n",
    "                    frame=d['frame'], unit=d['unit'])\n",
    "\n",
    "with open(\"sunspot_data.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "#Convert strings back into necessary datatypes\n",
    "for entry in data:\n",
    "    if 'times' in entry:\n",
    "        entry['times'] = [datetime.fromisoformat(t) if isinstance(t, str) else t for t in entry['times']]\n",
    "    if 'positions_helio' in entry:\n",
    "        entry['positions_helio'] = [dict_to_skycoord(coord) if isinstance(coord, SkyCoord) else coord for coord in entry['positions_helio']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the same visualization code from before and match the coordinates of specific identified features with the centroids. This method is not perfect as I used a rudamentary, greedy assignment method. Possible improvements would be a 1:1 matching method rather than a FIFO approach; using velocity as a predictor and using precision markers (closest wins the identifier); Merge short tracks (although it'd be hard to know which to merge); and adding a Kalman filter for predictive smoothing. \n",
    "\n",
    "Aside from that, the identifiers can be visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d583a7585cf455ab27fe8e1cd00d941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Select Day:', options=('20250422', '20250423', '20250424', '202504…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dropdown to select days\n",
    "day_dirs = sorted([d for d in os.listdir(\"sdo_hmi_jpgs\") if os.path.isdir(os.path.join(\"sdo_hmi_jpgs\", d))])\n",
    "@interact(day=Dropdown(options=day_dirs, description=\"Select Day:\"))\n",
    "def show_day_images(day):\n",
    "    day_path = os.path.join(\"sdo_hmi_jpgs\", day)\n",
    "    files = sorted([f for f in os.listdir(day_path) if f.endswith(\".jpg\")])[:16] #Only the first 12 images\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 4, figsize=(15, 10))\n",
    "    for ax, file in zip(axes.flat, files):\n",
    "        img, centroids, _, _ = detect_sunspots(os.path.join(day_path, file))\n",
    "        print(centroids)\n",
    "        \n",
    "        ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        ax.scatter([c[0] for c in centroids], [c[1] for c in centroids], s=5, c='red')\n",
    "        matches = []\n",
    "        for i, coords in enumerate(centroids):\n",
    "            for track_idx, track in enumerate(data):\n",
    "                for j, pos_px in enumerate(track['positions_px']):\n",
    "                    if list(coords) == pos_px:\n",
    "                        matches.append([i,track_idx])\n",
    "        \n",
    "        for centroid_idx, track_id in matches:\n",
    "            x,y = centroids[centroid_idx]\n",
    "            ax.text(x + 3, y + 3, str(track_id), color='blue', fontsize=8, weight='bold')\n",
    "            \n",
    "        \n",
    "        \n",
    "        ax.set_title(file.split('_')[1])  # Show time (hhmm)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the same spot often jumps to another identifier. This shouldn't be too much of an issue as you can see below, the average track length is 4—which is a pretty decent sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point 0: len = 10\n",
      "point 1: len = 1\n",
      "point 2: len = 14\n",
      "point 3: len = 13\n",
      "point 4: len = 2\n",
      "point 5: len = 2\n",
      "point 6: len = 3\n",
      "point 7: len = 11\n",
      "point 8: len = 11\n",
      "point 9: len = 3\n",
      "point 10: len = 6\n",
      "point 11: len = 8\n",
      "point 12: len = 1\n",
      "point 13: len = 2\n",
      "point 14: len = 2\n",
      "point 15: len = 3\n",
      "point 16: len = 6\n",
      "point 17: len = 2\n",
      "point 18: len = 15\n",
      "point 19: len = 2\n",
      "point 20: len = 8\n",
      "point 21: len = 1\n",
      "point 22: len = 3\n",
      "point 23: len = 1\n",
      "point 24: len = 1\n",
      "point 25: len = 1\n",
      "point 26: len = 3\n",
      "point 27: len = 3\n",
      "point 28: len = 1\n",
      "point 29: len = 1\n",
      "point 30: len = 1\n",
      "point 31: len = 4\n",
      "point 32: len = 1\n",
      "point 33: len = 2\n",
      "point 34: len = 2\n",
      "point 35: len = 1\n",
      "point 36: len = 3\n",
      "point 37: len = 2\n",
      "point 38: len = 2\n",
      "point 39: len = 3\n",
      "point 40: len = 1\n",
      "point 41: len = 1\n",
      "point 42: len = 7\n",
      "point 43: len = 1\n",
      "point 44: len = 1\n",
      "point 45: len = 2\n",
      "point 46: len = 1\n",
      "point 47: len = 2\n",
      "point 48: len = 2\n",
      "point 49: len = 1\n",
      "point 50: len = 10\n",
      "point 51: len = 3\n",
      "point 52: len = 6\n",
      "point 53: len = 2\n",
      "point 54: len = 5\n",
      "point 55: len = 2\n",
      "point 56: len = 12\n",
      "point 57: len = 3\n",
      "point 58: len = 1\n",
      "point 59: len = 2\n",
      "point 60: len = 1\n",
      "point 61: len = 3\n",
      "point 62: len = 1\n",
      "point 63: len = 1\n",
      "point 64: len = 2\n",
      "point 65: len = 8\n",
      "point 66: len = 2\n",
      "point 67: len = 1\n",
      "point 68: len = 9\n",
      "point 69: len = 2\n",
      "point 70: len = 2\n",
      "point 71: len = 3\n",
      "point 72: len = 21\n",
      "point 73: len = 6\n",
      "point 74: len = 4\n",
      "point 75: len = 5\n",
      "point 76: len = 3\n",
      "point 77: len = 1\n",
      "point 78: len = 2\n",
      "point 79: len = 4\n",
      "point 80: len = 3\n",
      "point 81: len = 1\n",
      "point 82: len = 1\n",
      "point 83: len = 4\n",
      "point 84: len = 3\n",
      "point 85: len = 1\n",
      "point 86: len = 13\n",
      "point 87: len = 14\n",
      "point 88: len = 2\n",
      "point 89: len = 2\n",
      "point 90: len = 1\n",
      "point 91: len = 4\n",
      "point 92: len = 6\n",
      "point 93: len = 15\n",
      "point 94: len = 5\n",
      "point 95: len = 5\n",
      "point 96: len = 1\n",
      "point 97: len = 1\n",
      "point 98: len = 1\n",
      "point 99: len = 2\n",
      "point 100: len = 2\n",
      "point 101: len = 2\n",
      "point 102: len = 5\n",
      "point 103: len = 3\n",
      "point 104: len = 18\n",
      "point 105: len = 2\n",
      "point 106: len = 4\n",
      "point 107: len = 3\n",
      "point 108: len = 1\n",
      "point 109: len = 4\n",
      "point 110: len = 16\n",
      "point 111: len = 5\n",
      "point 112: len = 2\n",
      "point 113: len = 2\n",
      "point 114: len = 3\n",
      "point 115: len = 1\n",
      "point 116: len = 2\n",
      "point 117: len = 1\n",
      "point 118: len = 2\n",
      "point 119: len = 11\n",
      "point 120: len = 1\n",
      "point 121: len = 5\n",
      "point 122: len = 6\n",
      "point 123: len = 3\n",
      "point 124: len = 1\n",
      "point 125: len = 2\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#Number of datapoints for each feature\n",
    "lengths = []\n",
    "for i,entry in enumerate(data):\n",
    "    print(f\"point {i}: len = {len(entry['velocities'])}\")\n",
    "    lengths.append(len(entry))\n",
    "print(sum(lengths)/len(lengths))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with 117 detected features with atleast one velocity datapoint, we can start the data analysis. Everything up to this point was extracting velocity data. There are many improvements which could be done (as stated in a markdown above the visualization with the identifiers for the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to try:\n",
    "- Plotting angular velocity by latitude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOHO_DML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
